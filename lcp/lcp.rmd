---
title: "Deep learning analysis of lung nodules decreases false positive rate in the National Lung Screening Trial"
output:
  word_document:
    reference_docx: style.docx
bibliography: bibliography.bib
csl: journal-of-the-national-cancer-institute.csl
---

```{r include=FALSE, cache=FALSE}
library(knitr)
library(here)
```

Introduction {#introduction .unnumbered}
========================================

Low-dose Computed Tomography (LDCT) images collected during epidemiological
studies, clinical trials, and routine screening represent an opportunity to
improve the accuracy of cancer risk predictions. LDCT imaging is an effective
modality for early detection and diagnosis of lung cancer. The National Lung
Screening Trial (NLST) reported a 20% reduction in mortality in the LDCT arm
relative to the standard X-ray arm [@nlst2011].

The use of LDCT for lung cancer screening is not without limitations, however,
and current obstacles include
- high inter-rater variability, i.e. differences among the assessments of
  different clinicians and
- high false positive rates, i.e. detecting cancer in individuals without
  cancer.
In the NLST, for example, roughly a quarter (26.6%) of the positive baseline
LDCT scans did not result in a cancer diagnosis [@nlst2011]. Methods to improve
the false positive rate have been successfully implemented [@pinsky2015], but
false positives remain a major concern.

In an effort to overcome the limitations described above, we aim to develop
lung cancer risk prediction models that can integrate LDCT image features with
established risk factors. Current statistical models used to assess cancer risk
focus on well-described risk factors, such as smoking, and demographic factors,
like race [@katki2018]. Integrating image data into statistical models
represents a significant challenge, because of the computational requirements
and technical expertise required to extract image features as numeric variables
that can be used in statistical models.

To tackle this challenge, we set out to develop lung cancer risk prediction
models that could integrate physician-annotated and algorithmically derived
LDCT image features with established risk factors. To evaluate the feasibility and
utility of this approach, we analyzed LDCT images obtained from the National
Lung Screening Trial (NLST).

As a proof of principle, we used an deep learning algorithm developed for
discrimination of malignant and benign nodules, to see whether it could improve
a clinical model for the prediction of a screening patient's likelihood of
developing cancer over the upcoming year. The existing model used a number of
features extracted from the metadata of the US National Lung Screening Trial
(NLST) to produce a likelihood score of developing cancer before the
corresponding screening image taken the following year. These features included
both patient clinical data (age, smoking history etc), and quantities extracted
from a radiological read of the screening CT, such as maximal nodule size, the
existence of any GGO nodules on the CT, and presence of emphysema within the
patient.

Methods {#methods .unnumbered}
==============================

We set out to evaluate the utility of combining 1) the Lung Cancer Prediction
Convolutional Neural Network (LCP-CNN) [@Baldwin_2020], a deep learning
algorithm developed to classify nodules as malignant or benign, and 2) the Lung
Cancer Risk Assessment Tool (LCRAT) [@Katki_2016], a statistical model that
assesses cancer risk based on prescreening factors. Towards this goal, we first
prepared a re-curated version of the National Lung Screening Trial (NLST)
[@NLST_2011] dataset. To create the re-curated NLST dataset, medical doctors or
medical students, under expert supervision from University of Oxford
Radiologists, reviewed and extended metadata related to a subset of NLST
Low-dose Computed Tomography (LDCT) scans.

The LDCT scan subset included 1) scans listed as containing at least one
nodule, 2) scans that contained non-calcified nodules not listed in the
original NLST metadata, and 3) scans of all NLST participants recorded as
having developed lung cancer. In particular, the size, extent, location,
margins and attenuation of each nodule were reviewed by the same small team of
individuals, and the exact 3D location of each nodule was identified and
recorded. NLST participant who never had any reported nodules and also never
developed lung cancer did not have their scans reviewed.

Before training LCP-CNN on the LDCT scan subset, we first used transfer
learning to pre-train the algorithm on hundreds of thousands of non-NLST
images. We then trained the LCP-CNN to discriminate between malignant and
benign nodules. We used class balancing to overcome the much higher frequency
of individuals who did not develop cancer compared to cancer cases in the NLST
dataset. We performed 8-fold cross-validation and generated LCP scores for each
nodule in all eight test folds. LCP scores range between 0 and 1, where scores
closer to 1 indicate malignancy. We decided to focus on only the highest
scoring nodules and considered the maximum LCP score observed in each scan to
be the final LCP-CNN output.

In parallel to the deep learning work described above, we used obtained
prescreening risk predictions for all NSLT participants using LCRAT
[@Katki_2016]. Unlike LCP-CNN, LCRAT does not use image data and instead
calculates prescreening cancer risk based on 12 known cancer risk factors. We
developed data processing pipelines in the R programming language [@R_2019] to
integrate clinical and epidemiologic data from the NLST with features that we
extracted from the LDCT scan images using 3D CNNs. After training LCRAT on data
from the Prostate, Lung, Colorectal, and Ovarian Cancer Screening Trial (PLCO)
[@PLCO_2000], we predicted the prescreening risks of all NLST participants. We
then sought to integrate prescreening risk prediction with deep learning image
analysis by passing prescreening risks and LCP scores to a combiner algorithm
trained to predict cancer cases in the subsequent screening year. In essence,
our approach is to update prescreening risk, calculated from known risk
factors, with information obtained from LDCT scans.

We then using the stats and yardstick R packages [@R_2019; @Kuhn_2019] to
compare the performance of the combiner algorithm when provided LCP scores and
prescreening risks against either of the two inputs alone. The addition of
prescreening risk improved cancer risk prediction performance when compared to
LCP score alone (Table 1) with a likelihood ratio test (p-value: 0.00431), but
the improvements in Akaike Information Criterion (AIC) and Area Under the ROC
Curve (AUROC) were minimal (AIC: 1514 versus 1520; AUROC: 0.851 versus 0.850).

To visually compare the models, we plotted the sensitivity (recall) against the
proportion of participants in annual versus biennial screening (Figure 1) using
the ggplot R package [@Wickham_2016]. This type of plot is referred to as
a gain curve by the yardstick package. The plot shows the sensitivity gained by
shifting individuals from biennial to annual screening. Like the AIC and AUROC
values in Table 1, Figure 1 shows that the model using LCP scores to predict
cancer outperforms the model using prescreening risks alone. Adding
prescreening risk on top of LCP scores does not lead to an easily discernible
difference.

To improve the model further, we included LDCT scan information annotated by
physicians in addition to the LCP scores and prescreening risks. Previously,
our group has shown that prescreening risk, calculated with the Lung Cancer
Risk Assessment Tool (LCRAT) model [@katki2018], can be combined with physician
annotations of lung conditions detected by LDCT to more accurately predict lung
cancer risk [@@Robbins_2019]. This approach, named LCRAT+CT [@Robbins_2019], is
essentially a version of LCRAT that includes physician annotated features.
Unlike LCRAT+CT, we focused on LDCT features only present in positive scans,
such as the location of the nodule in the lungs.


Results {#results .unnumbered}
==============================

We should defer writing up any results until we've reached consensus
with everything above.
most of this is required during training and not during deployment.

Discussion {#discussion .unnumbered}
==========

The results presented here show that 3D CNN-based approaches are a promising
direction of research for computer-aided prediction of a future cancer
diagnosis. As well as just diagnosing cancer, neural networks could identify
multiple CT-diagnosed diseases to identify risk factors for lung cancer, or
even identify lung cancer risk directly.
Furthermore, the neural network may be useful as significantly more robust than the density mask approach, even with a
very basic network.

When applied to data obtained from Low-Dose Computed Tomography (LDCT) lung
cancer screening, a Convolutional Neural Network (CNN) can yield information on
entire organs, like the lungs or heart, or specific regions of interest, such
as any existing lung cancer nodules. Essentially, CNNs are algorithms that
distill complex data, typically images, into simpler outputs. Each CNN must be
trained to perform a specific task. In particular, we trained CNNs to generate
quantitative estimates of the severity of
- heart conditions like coronary artery calcification, and lung conditions like
  emphysema, adenopathy, and consolidation.
We hypothesize that these health condition estimates will allow us to gain
valuable insight into the risks of lung cancer, chronic obstructive pulmonary
disease, and heart disease.

In essence, our approach is to update prescreening risk, calculated using
standard lung cancer risk prediction models, with information derived from LDCT
screening by CNNs. We have previously demonstrated the utility of a similar
approach that used physician annotations of LDCT screens. For example, we have
shown that LDCT scans annotated by physicians as emphysematous are associated
with increased lung cancer risk. Building on our previous work, we endeavor to
develop a model that will aggregate the results of a prescreening risk model
and multiple CNNs into a single lung cancer risk prediction. We hypothesize
that a model which uses image features provided by a CNN instead of
physician-annotated features will similarly result in a better risk assessment
than prescreening risk alone, but without the need for physicians to manually
annotate LDCT scans.

As part of this work, we will develop an image analysis pipeline that trains
three-dimensional convolutional neural networks (3D CNN) to distill LDCT lung
scans into variables for lung cancer risk prediction models. A 3D CNN utilizes
multiple layers of convolutions to detect features all throughout a lung scan,
as opposed to a two-dimensional CNN which extracts feature from a single image
slice at a time. 3D CNN have the potential to yield improved results, but
require far greater computational resources than 2D CNN.

Algorithmic feature extraction from LDCT images offers many advantages over
manual annotation of images by physicians. In particular, CNN image feature
extraction is quantitative and can be automated to as part of systems that
supply image features for downstream lung cancer risk prediction models or that
output predicted lung cancer risk directly. These images features can also be
used to identify conditions that may be associated with lung cancer risk, like
emphysema.

The work described here will constitute a proof of principle of cancer risk
modeling methods that combine algorithmic imaging analysis techniques with
classical cancer risk modeling. Algorithmic feature extraction from LDCT images
offers many advantages over manual annotation of images by physicians. In
particular, algorithms can be automated and yield quantitative results, whereas
image annotation by physicians is tedious and difficult to quantify.
Furthermore, the reproducibility and reliability of algorithmic approaches can
be ensured through software engineering best practices.

While our current focus is lung cancer, the methods we will develop could
potentially be adapted for other cancer types. For example, it may be possible
employ a similar approach using image data from other medical screening
modalities, such as mammograms to improve breast cancer risk prediction or
colposcopic images to assess cervical cancer risk. Similarly, we  can extend
the utility of our proposed approach beyond cancer by shifting our focus to
LDCT image characteristics related to heart disease and chronic obstructive
pulmonary disease. The ultimate goal of this work is to highlight the
importance of screening, inform screening guidelines, and provide individuals
with improved assessments of their health risks.

Integrating heterogeneous data into statistical models represents a significant
technical challenge. The work described here constitutes a proof of principle
of a cancer risk modeling method that combines imaging analysis techniques with
classical cancer risk modeling. Current statistical models used to assess
cancer risk focus on well-described risk factors, such as smoking, and
demographic factors, such as race and ethnicity.

Low-dose Computed Tomography (LDCT) images collected during epidemiological
studies, clinical trials, and routine screening represent an opportunity to
improve the accuracy of cancer risk predictions. LDCT imaging is an effective
modality for early detection and diagnosis of lung cancer. The use of LDCT for
lung cancer screening is not without limitations, however, and current
obstacles include 1) high inter-rater variability, i.e. differences among the
assessments of different clinicians and 2) high false positive rates, i.e.
detecting cancer in individuals without cancer.

Neural networks are often referred to as "black box" models, because it is very
difficult to explain exactly what inputs result in a given output. We can use a
technique called local interpretable model-agnostic explanations to pinpoint
exactly what parts an image influence cancer risk, but this information is
still be difficult to interpret. In contrast, if we obtain an estimate of lung
condition severity from image data, we can then use interpretable statistical
models to analyze how that lung condition affects lung cancer risk. In essence,
the approach we are proposing combines the interpretability of classical
statistical modeling with the ability of neural networks to extract information
from images. We hypothesize that this combined model will have comparable
predictive performance to a CNN that predicts lung cancer risk directly, but
will additionally help to elucidate the factors that influence predictions.

In the case of LDCT scans with identifiable lung cancer nodules, CNNs can
provide a quantitative malignancy score based on nodule features. Malignancy
scores can help distinguish between malignant and benign nodules, inform
prognosis, and avoid unneeded interventions in response to the discovery of
insignificant nodules. This approach focuses on the nodules and thus loses the
context of the surrounding lung. We propose an alternate approach that uses a
malignancy score produced by a CNN in addition to prescreening risk and
information on lung condition obtained from physician annotation or using a
CNN. We hypothesize that by taking into account prescreening risk and the state
of the surrounding lungs we can avoid more false positives than with a
CNN-derived malignancy score alone.

Tables {#tables .unnumbered}
======

Table 1: Model Table
```{r echo=FALSE}
kable(readRDS(here("lcp/tables/model_table.rds")), "markdown")
```

Table 2: Variable Table
```{r echo=FALSE}
kable(readRDS(here("lcp/tables/variable_table.rds")), "markdown")
```

Table 3: Risk Table
```{r echo=FALSE}
kable(readRDS(here("lcp/tables/lcp_risk_table.rds")), "markdown")
```

Figures {#figures .unnumbered}
=======

Figure 1: Lorenz curve

```{r echo=FALSE}
include_graphics(here("lcp/lorenz.png"))
```

